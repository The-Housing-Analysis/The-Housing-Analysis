# -*- coding: utf-8 -*-
"""The_Housing_Analysis_Amenities.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P8HuA9aCWd75moa_aexVuj62KH1HwWuu
"""

#Import packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#Import Csvs
# data2023 = pd.read_csv('/content/ACSDP1Y2023.DP04-Data.csv')
# data2018 = pd.read_csv('/content/ACSDP1Y2018.DP04-Data.csv')
# data2013 = pd.read_csv('/content/ACSDP1Y2013.DP04-Data.csv')
data2013 = pd.read_csv('https://raw.githubusercontent.com/The-Housing-Analysis/The-Housing-Analysis/refs/heads/main/data/ACSDP1Y2013.DP04-Data.csv')
data2018 = pd.read_csv('https://raw.githubusercontent.com/The-Housing-Analysis/The-Housing-Analysis/refs/heads/main/data/ACSDP1Y2018.DP04-Data.csv')
data2023 = pd.read_csv('https://raw.githubusercontent.com/The-Housing-Analysis/The-Housing-Analysis/refs/heads/main/data/ACSDP1Y2023.DP04-Data.csv')


#Update headers to row0 values
data2023 = data2023.rename(columns=data2023.iloc[0]).drop(data2023.index[0])
data2018 = data2018.rename(columns=data2018.iloc[0]).drop(data2018.index[0])
data2013 = data2013.rename(columns=data2013.iloc[0]).drop(data2013.index[0])

#Add year column to each dataset
data2023['Year'] = "2023"
data2018['Year'] = "2018"
data2013['Year'] = "2013"

#Reset indices
data2023 = data2023.reset_index(drop=True)
data2018 = data2018.reset_index(drop=True)
data2013 = data2013.reset_index(drop=True)

#Preview data2023
data2023

#Preview data2018
data2018

#Preview data2013
data2013

#Append data frames together
housingData = pd.concat([data2023, data2018], axis = 0, ignore_index=True)
#housingData = housingData.reset_index(drop=True)
#housingData = pd.concat([housingData, data2013], axis = 0, ignore_index=True)
housingData

#Need to weed  out unwanted columns

#Need to add Country, State, County column
#(I think we can use the Geography column for codes starting in 01, 04, or 05)

# function to retain columns with Estimate
def clean_column_names(cols):
    cols = [col for col in cols if type(col)==str]
    cols_retain = []
    for col in cols:
        if '!!' not in col:
            cols_retain.append(col)
        elif col.startswith('Estimate!!'):
            cols_retain.append(col)

    return cols_retain

# get YEAR STRUCTURE BUILT appended across all datasets
def get_build_year_info(df):
    build_year_info = []
    for col in df.columns:
        if type(col) == str:
            if 'Estimate!!YEAR STRUCTURE BUILT' in col:
                build_year_info.append(col)

    return build_year_info

# run get_build_year_info for all datasets
build_year_info_2013 = set(get_build_year_info(data2013))
build_year_info_2018 = set(get_build_year_info(data2018))
build_year_info_2023 = set(get_build_year_info(data2023))

# create unique build year information list
build_year_info = list(build_year_info_2013.union(build_year_info_2018).union(build_year_info_2023))

# create build year information columns into each dataset
for build_year in build_year_info:
    if build_year not in data2013.columns:
        print(build_year)
        data2013[build_year] = 0
    if build_year not in data2018.columns:
        print(build_year)
        data2018[build_year] = 0
    if build_year not in data2023.columns:
        print(build_year)
        data2023[build_year] = 0

# run clean columns
cleaned_13 = clean_column_names(data2013.columns)
cleaned_18 = clean_column_names(data2018.columns)
cleaned_23 = clean_column_names(data2023.columns)

# columns contained in all
cols_all = list(set(cleaned_13).intersection(set(cleaned_18), set(cleaned_23)))

# select matching columns in datasets
subset_13 = data2013[cols_all]
subset_18 = data2018[cols_all]
subset_23 = data2023[cols_all]

# concat data
df = pd.concat([subset_13, subset_18])
df = pd.concat([df, subset_23])

# function to look at tiered column structure
# note: returns as list, wrap result in pd.DataFrame() to get nicely structured result
def tier_columns(cols, split_criteria='!!'):
    column_tiers = []
    for col in cols:
        column_tiers.append(col.split(split_criteria))

    return column_tiers

# columns with tier_2 null values to drop
drop_initial = ['BEDROOMS', 'GRAPI', 'HOUSE HEATING FUEL', 'HOUSING OCCUPANCY', 'HOUSING TENURE', 'MORTGAGE STATUS', 'OCCUPANTS PER ROOM', 'ROOMS', 'SMOC', 'SELECTED CHARACTERISTICS', 'SMOCAPI', 'UNITS IN STRUCTURE', 'VALUE', 'VEHICLES AVAILABLE', 'YEAR HOUSEHOLDER MOVED INTO UNIT', 'YEAR STRUCTURE BUILT']
# columns without tier_2 null values to drop
drop_secondary = ['GROSS RENT', 'SMOC', 'YEAR HOUSEHOLDER MOVED INTO UNIT']
# specific columns without tier_2 null values to drop
drop_tertiary = ['ROOMS!!Total!!Median rooms', 'VALUE!!Owner Occupied!!Median (dollars)']

# function for initial renaming of columns (result retains !! format)
def rename_columns(df, drop_initial, drop_secondary, drop_tertiary):
    # copy of df
    df_rename = df.copy()

    # take away estimate
    df_rename.columns = df_rename.columns.str.replace('Estimate!!', '')

    # rename GRAPI - initial
    df_rename.columns = df_rename.columns.str.replace('GROSS RENT AS A PERCENTAGE OF HOUSEHOLD INCOME (GRAPI)', 'GRAPI', regex=False)

    # rename SMOC - initial
    df_rename.columns = df_rename.columns.str.replace('SELECTED MONTHLY OWNER COSTS (SMOC)', 'SMOC', regex=False)

    # rename SMOCAPI - initial
    df_rename.columns = df_rename.columns.str.replace('SELECTED MONTHLY OWNER COSTS AS A PERCENTAGE OF HOUSEHOLD INCOME (SMOCAPI)', 'SMOCAPI', regex=False)

    # rename GRAPI - secondary
    df_rename.columns = df_rename.columns.str.replace('Occupied units paying rent (excluding units where GRAPI cannot be computed)', 'Occupied units paying rent', regex=False)

    # rename SMOCAPI - secondary with mortgage information
    df_rename.columns = df_rename.columns.str.replace('Housing units with a mortgage (excluding units where SMOCAPI cannot be computed)', 'Housing units with a mortgage', regex=False)
    df_rename.columns = df_rename.columns.str.replace('Housing unit without a mortgage (excluding units where SMOCAPI cannot be computed)', 'Housing units without a mortgage', regex=False)

    # rename second tiers
    df_rename.columns = df_rename.columns.str.replace('Total housing units', 'Total', regex=False)
    df_rename.columns = df_rename.columns.str.replace('Occupied units paying rent', 'Rent', regex=False)
    df_rename.columns = df_rename.columns.str.replace('Occupied housing units', 'Occupied', regex=False)
    df_rename.columns = df_rename.columns.str.replace('Vacant housing units', 'Vacant', regex=False)
    df_rename.columns = df_rename.columns.str.replace('Owner-occupied units', 'Owner Occupied', regex=False)
    df_rename.columns = df_rename.columns.str.replace('Housing units with a mortgage', 'With Mortgage', regex=False)
    df_rename.columns = df_rename.columns.str.replace('Housing units without a mortgage', 'Without Mortgage', regex=False)

    # non-static columns
    static_columns = ['Year', 'Geography', 'Geographic Area Name']
    df_cols = [col for col in df_rename.columns if col not in static_columns]

    # apply tier_columns function
    df_tiers = pd.DataFrame(tier_columns(df_cols))
    df_tiers.columns = [f'tier_{col}' for col in range(df_tiers.shape[1])]

    # drop with null
    drop_cols = []
    for index, row in df_tiers.iterrows():
        tier_0 = row['tier_0']
        tier_1 = row['tier_1']
        tier_2 = row['tier_2']
        if (tier_2 is None) & (tier_0 in drop_initial):
            drop_cols.append(f'{tier_0}!!{tier_1}')
        elif(tier_2 is not None) & (tier_0 in drop_secondary):
            drop_cols.append(f'{tier_0}!!{tier_1}!!{tier_2}')

    drop_cols = drop_cols + drop_tertiary
    retain_cols = [col for col in df_rename.columns if col not in drop_cols]
    retain_cols.sort()
    df_final = df_rename[retain_cols]

    return df_final

# run initial rename function
df_renamed = rename_columns(df, drop_initial, drop_secondary, drop_tertiary)
new_cols = df_renamed.columns

# tiers
new_tiers = pd.DataFrame(tier_columns(new_cols))

# show new tiers
new_tiers

# function for the final restructure - removes '!!' format
def finalize_restructure(df):
    df_cols = df.columns
    df_tiers = pd.DataFrame(tier_columns(df_cols))
    df_tiers.columns = [f'tier_{col}' for col in range(df_tiers.shape[1])]

    col_remapping = {}
    for index, row in df_tiers.iterrows():
        tier_0 = row['tier_0']
        tier_1 = row['tier_1']
        tier_2 = row['tier_2']

        if tier_0 == 'BEDROOMS':
            # n bedroom(s)
            col_remapping[df_cols[index]] = tier_2
        elif tier_0 == 'GRAPI':
            # GRAPI - percent
            col_remapping[df_cols[index]] = f'GRAPI - {tier_2}'
        elif tier_0 == 'GROSS RENT':
            # Rent
            col_remapping[df_cols[index]] = tier_1
        elif tier_0 == 'HOUSE HEATING FUEL':
            # Heat - type
            col_remapping[df_cols[index]] = f'Heat - {tier_2}'
        elif tier_0 == 'HOUSING OCCUPANCY':
            # either Vacant or Occupied
            col_remapping[df_cols[index]] = tier_2
        elif tier_0 == 'HOUSING TENURE':
            # either (Owner-occupied or Renter-occupied)
            col_remapping[df_cols[index]] = tier_2
        elif tier_0 == 'MORTGAGE STATUS':
            # either With or Without (both classes are Owner Occupied)
            col_remapping[df_cols[index]] = tier_2
        elif tier_0 == 'OCCUPANTS PER ROOM':
            # Occupants - avg
            col_remapping[df_cols[index]] = f'Occupants - {tier_2}'
        elif tier_0 == 'ROOMS':
            # n room(s)
            col_remapping[df_cols[index]] = tier_2
        elif tier_0 == 'SELECTED CHARACTERISTICS':
            # type of services lacking
            col_remapping[df_cols[index]] = tier_2
        elif tier_0 == 'SMOCAPI':
            # SMOCAPI - mortgage status - percent
            col_remapping[df_cols[index]] = f'{tier_0} - {tier_1} - {tier_2}'
        elif tier_0 == 'UNITS IN STRUCTURE':
            # type and/or number of units in structure
            col_remapping[df_cols[index]] = tier_2
        elif tier_0 == 'VALUE':
            # value ranges
            col_remapping[df_cols[index]] = tier_2
        elif tier_0 == 'VEHICLES AVAILABLE':
            # vehicle spaces available
            col_remapping[df_cols[index]] = tier_2
        elif tier_0 == 'YEAR STRUCTURE BUILT':
            # date range of structures built
            col_remapping[df_cols[index]] = tier_2

    # apply remapping
    df_final = df.rename(columns=col_remapping)

    return df_final

# run final restructure
df_final = finalize_restructure(df_renamed)

# function to fix N and (X) and create numeric on specific columns
def fix_numeric_cols(df):
    ignore_cols = ['Year', 'Geography', 'Geographic Area Name']
    fix_cols = [col for col in df.columns if col not in ignore_cols]
    df.loc[:, fix_cols] = df.loc[:, fix_cols].replace('N', 0)
    df.loc[:, fix_cols] = df.loc[:, fix_cols].replace('(X)', 0)

    issue_cols = []
    for col in fix_cols:
        try:
            df[col] = df[col].astype(int)
        except ValueError:
            issue_cols.append(col)

    return df, issue_cols

# run numeric fix
final_df, issues = fix_numeric_cols(df_final)

# create description of data
final_describe = final_df.describe()

final_df.head()

final_describe

final_df.columns

#Find difference in country stats between 2013 and 2018 data
final_df_2013to18 = final_df[(final_df['Year'] == '2013')|(final_df['Year'] == '2018')]
final_df_2013to18 = final_df_2013to18.sort_values(by=['Year'], ascending=True)
final_df_2013to18 = final_df_2013to18.reset_index(drop=True)
final_df_2013to18 = final_df_2013to18.drop(columns=['Year','Geography'])
final_df_2013to18 = final_df_2013to18.groupby(by = ['Geographic Area Name'], as_index = True)
final_df_2013to18 = final_df_2013to18.diff().dropna().reset_index()
final_df_2013to18 = final_df_2013to18.join(final_df['Geographic Area Name'].drop_duplicates().sort_values(ascending = True))
final_df_2013to18 = final_df_2013to18[final_df_2013to18.columns[-1:].tolist() + final_df_2013to18.columns[:-1].tolist()] #Moves Geography Name to first column
final_df_2013to18["Time Period"] = "2013-2018"
final_df_2013to18

#Find difference in country stats between 2018 and 2023 data
final_df_2018to23 = final_df[(final_df['Year'] == '2018')|(final_df['Year'] == '2023')]
final_df_2018to23 = final_df_2018to23.sort_values(by=['Year'], ascending=True)
final_df_2018to23 = final_df_2018to23.reset_index(drop=True)
final_df_2018to23 = final_df_2018to23.drop(columns=['Year','Geography'])
final_df_2018to23 = final_df_2018to23.groupby(by = ['Geographic Area Name'], as_index = True)
final_df_2018to23 = final_df_2018to23.diff().dropna().reset_index()
final_df_2018to23 = final_df_2018to23.join(final_df['Geographic Area Name'].drop_duplicates().sort_values(ascending = True))#Merge Geo Names back in
final_df_2018to23 = final_df_2018to23[final_df_2018to23.columns[-1:].tolist() + final_df_2018to23.columns[:-1].tolist()] #Moves Geography Name to first column
final_df_2018to23["Time Period"] = "2018-2023"
#final_df_2018to23

#Append data frames together
#final_differences = pd.concat([final_df_2013to18, final_df_2018to23], axis = 0, ignore_index=True)
#final_differences = final_differences.rese
#final_differences

final_df.head()

#final_df.columns

# identify amenity columns
columns_to_keep = [
    'Geographic Area Name',
    'Heat - Bottled, tank, or LP gas',
    'Heat - Coal or coke',
    'Heat - Electricity',
    'Heat - Fuel oil, kerosene, etc.',
    'Heat - No fuel used',
    'Heat - Other fuel',
    'Heat - Solar energy',
    'Heat - Utility gas',
    'Heat - Wood',
    'Occupied',
    'Vacant',
    'Owner-occupied',
    'Renter-occupied',
    'Lacking complete kitchen facilities',
    'Lacking complete plumbing facilities',
    'No telephone service available',
    '1 vehicle available',
    '2 vehicles available',
    '3 or more vehicles available',
    'No vehicles available'
]

final_df_utilities = final_df[columns_to_keep]

final_df_utilities = final_df_utilities[1:52].reset_index(drop=True)
#final_df_utilities

# assign states to regions
state_to_region = {
    # west
    'Alaska': 'West', 'Arizona': 'West', 'California': 'West', 'Colorado': 'West',
    'Hawaii': 'West', 'Idaho': 'West', 'Montana': 'West', 'Nevada': 'West',
    'New Mexico': 'West', 'Oregon': 'West', 'Utah': 'West', 'Washington': 'West', 'Wyoming': 'West',

    # midwest
    'Illinois': 'Midwest', 'Indiana': 'Midwest', 'Iowa': 'Midwest', 'Kansas': 'Midwest',
    'Michigan': 'Midwest', 'Minnesota': 'Midwest', 'Missouri': 'Midwest', 'Nebraska': 'Midwest',
    'North Dakota': 'Midwest', 'Ohio': 'Midwest', 'South Dakota': 'Midwest', 'Wisconsin': 'Midwest',

    # northeast
    'Connecticut': 'Northeast', 'Maine': 'Northeast', 'Massachusetts': 'Northeast',
    'New Hampshire': 'Northeast', 'New Jersey': 'Northeast', 'New York': 'Northeast',
    'Pennsylvania': 'Northeast', 'Rhode Island': 'Northeast', 'Vermont': 'Northeast',

    # south
    'Alabama': 'South', 'Arkansas': 'South', 'Delaware': 'South', 'Florida': 'South',
    'Georgia': 'South', 'Kentucky': 'South', 'Louisiana': 'South', 'Maryland': 'South',
    'Mississippi': 'South', 'North Carolina': 'South', 'Oklahoma': 'South', 'South Carolina': 'South',
    'Tennessee': 'South', 'Texas': 'South', 'Virginia': 'South', 'West Virginia': 'South', 'District of Columbia': 'South'
}

# Map states to regions
final_df_utilities['Region'] = final_df_utilities['Geographic Area Name'].map(state_to_region)

#final_df_utilities.head()

#final_df_utilities

# build stacked bar chart for heating type

heat_columns = [
    'Heat - Bottled, tank, or LP gas',
    'Heat - Coal or coke',
    'Heat - Electricity',
    'Heat - Fuel oil, kerosene, etc.',
    'Heat - No fuel used',
    'Heat - Other fuel',
    'Heat - Solar energy',
    'Heat - Utility gas',
    'Heat - Wood'
]

color_palette = sns.color_palette("Paired", len(heat_columns))

proportions_by_region = {}
for region in final_df_utilities['Region'].unique():
  region_df = final_df_utilities[final_df_utilities['Region'] == region]
  totals = region_df[heat_columns].sum()
  proportions_by_region[region] = totals / totals.sum()

proportions_df = pd.DataFrame(proportions_by_region, index=heat_columns)

plt.figure(figsize=(12, 6))
bottom = np.zeros(len(proportions_df.columns))

for i, heat_type in enumerate(proportions_df.index):
  plt.bar(
      proportions_df.columns,
      proportions_df.loc[heat_type],
      bottom=bottom,
      color=color_palette[i],
      label=heat_type
      )
  bottom += proportions_df.loc[heat_type]

plt.legend(title="Heating Types", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)
plt.title("Heating Type by Region", fontsize=14)
plt.xlabel("Region", fontsize=12)
plt.ylabel("Proportion", fontsize=12)
plt.tight_layout()
plt.show()

# bar chart comparing lack of kitchen proportions

proportions_kitchen = {}
for region in final_df_utilities['Region'].unique():
  region_df = final_df_utilities[final_df_utilities['Region'] == region]
  total = region_df[['Occupied', 'Vacant']].sum().sum()
  lacking_kitchen = region_df['Lacking complete kitchen facilities'].sum()
  proportions_kitchen[region] = lacking_kitchen / total

proportions_df = pd.DataFrame(list(proportions_kitchen.items()), columns=['Region', 'Proportion'])

proportions_df = proportions_df.sort_values(by='Proportion', ascending=True)

plt.figure(figsize=(6, 4))
sns.barplot(
    x='Proportion',
    y='Region',
    data=proportions_df,
    palette='Paired'
)

plt.xlabel('Proportion', fontsize=12)
plt.ylabel('Region', fontsize=12)
plt.title('Proportion of Lacking Complete Kitchen Facilities by Region', fontsize=14)
plt.tight_layout()
plt.show()

# bar chart comparing lack of plumbing proportions

proportions_plumbing = {}
for region in final_df_utilities['Region'].unique():
  region_df = final_df_utilities[final_df_utilities['Region'] == region]
  total = region_df[['Occupied', 'Vacant']].sum().sum()
  lacking_plumbing = region_df['Lacking complete plumbing facilities'].sum()
  proportions_plumbing[region] = lacking_plumbing / total

proportions_df = pd.DataFrame(list(proportions_plumbing.items()), columns=['Region', 'Proportion'])

proportions_df = proportions_df.sort_values(by='Proportion', ascending=True)

plt.figure(figsize=(6, 4))
sns.barplot(
    x='Proportion',
    y='Region',
    data=proportions_df,
    palette='Paired'
)

plt.xlabel('Proportion', fontsize=12)
plt.ylabel('Region', fontsize=12)
plt.title('Proportion of Lacking Complete Plumbing Facilities by Region', fontsize=14)
plt.tight_layout()
plt.show()

# bar chart comparing lack of telephone proportions

proportions_telephone = {}
for region in final_df_utilities['Region'].unique():
  region_df = final_df_utilities[final_df_utilities['Region'] == region]
  total = region_df[['Occupied', 'Vacant']].sum().sum()
  lacking_telephone = region_df['No telephone service available'].sum()
  proportions_telephone[region] = lacking_telephone / total

proportions_df = pd.DataFrame(list(proportions_telephone.items()), columns=['Region', 'Proportion'])

proportions_df = proportions_df.sort_values(by='Proportion', ascending=True)

plt.figure(figsize=(6, 4))
sns.barplot(
    x='Proportion',
    y='Region',
    data=proportions_df,
    palette='Paired'
)

plt.xlabel('Proportion', fontsize=12)
plt.ylabel('Region', fontsize=12)
plt.title('No telephone service available', fontsize=14)
plt.tight_layout()
plt.show()

# import libraries for DT
from sklearn.model_selection import train_test_split
from sklearn import tree
import graphviz

final_df_utilities = final_df_utilities.drop(columns = ['Geographic Area Name'])

# split data up into train and test sets
DT_train, DT_test = train_test_split(final_df_utilities, test_size = .3)

# set label for train and test sets
DT_train_label = DT_train["Region"]
DT_test_label = DT_test["Region"]

# drop label
DT_train = DT_train.drop(["Region"], axis=1)
DT_test = DT_test.drop(["Region"], axis=1)

# instantiate decision tree
myTree = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 4)

# fit DT model
myTree.fit(DT_train, DT_train_label)

# define feature names
FeatureNames = DT_train.columns.values

# define class names
ClassNames = myTree.classes_

# plot decision tree
plt.figure(figsize = (20, 10))
MyPlot = tree.plot_tree(myTree, feature_names = FeatureNames, class_names = ClassNames)
plt.show()